services:
  # --- Airflow metadata database (Postgres) ---
  airflow-db-project:
    container_name: airflow-db-project
    image: postgres:16.4
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - pgdata_airflow-project:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      retries: 5
    restart: always

  # --- ClickHouse Server (target DB) ---
  clickhouse-server-project:
    image: clickhouse/clickhouse-server
    container_name: clickhouse-server-project
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data-project:/var/lib/clickhouse/
      - ./sample_data:/var/lib/clickhouse/user_files
      - ./sql:/sql
    environment:
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: "12345678"
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8123/ping || exit 1"]
      interval: 10s
      retries: 10
    restart: always

  dbt-project:
    # dbt container for building and testing ClickHouse models
    build:
      context: .               # Build context is the current directory
      dockerfile: Dockerfile.dbt   # Use the Dockerfile in this directory to build dbt image
    container_name: dbt-project
    depends_on:
      - clickhouse-server-project      # Ensure ClickHouse starts before dbt
    volumes:
      - ./sample_data:/var/lib/clickhouse/user_files # Shared folder for input files
      - ./sql:/sql                                  # Shared SQL scripts
      - ./dbt_project:/dbt                                  # Mount local dbt project directory
    working_dir: /dbt          # Set dbt project directory as the working directory
    tty: true                  # Keep container running for interactive dbt commands

  # --- Airflow builder/init (builds custom image with plugin) ---
  airflow-init-project:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-init-project
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db init
        airflow users create \
          --username airflow \
          --password airflow \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com || true
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db-project:5432/airflow
      AIRFLOW_CONN_CLICKHOUSE_DEFAULT: clickhouse+native://default:12345678@clickhouse-server-project:9000/default
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./sample_data:/var/lib/clickhouse/user_files
    depends_on:
      - airflow-db-project
      - clickhouse-server-project
    restart: "no"

  # --- Airflow Webserver ---
  airflow-webserver-project:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-webserver-project
    #image: local/airflow-clickhouse:latest
    command: webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db-project:5432/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth"
      AIRFLOW_CONN_CLICKHOUSE_DEFAULT: clickhouse+native://default:12345678@clickhouse-server-project:9000/default
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./sample_data:/var/lib/clickhouse/user_files
    depends_on:
      - airflow-init-project
      - airflow-db-project
      - clickhouse-server-project
    restart: always

  # --- Airflow Scheduler ---
  airflow-scheduler-project:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-scheduler-project
    #image: local/airflow-clickhouse:latest
    command: scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db-project:5432/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW_CONN_CLICKHOUSE_DEFAULT: clickhouse+native://default:12345678@clickhouse-server-project:9000/default
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./sample_data:/var/lib/clickhouse/user_files
    depends_on:
      - airflow-init-project
      - airflow-db-project
      - clickhouse-server-project
    restart: always

volumes:
  pgdata_airflow-project:
  clickhouse_data-project:
